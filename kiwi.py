import docx2txt
from kiwipiepy import Kiwi
# Kiwi 형태소 분석기 객체 생성
kiwi = Kiwi(load_default_dict=True) 
# userDict 로드 
kiwi.load_user_dictionary('userDict.txt')

stopwords = ({'개발', '연구', '향상', '전략', '과정', '문제', '정의', '배포', '지원', '결과',
               '솔루션', '테스트', '시장', '진출', '높이기', '반영', '감시', '목적', '대상', '기능', '기술', '단계',
                 '방법', '활용', '환경', '사용', '라이브러리', '사용자', '이해', '적용', '성과', '개선', '개월', '계획',
                   '고려', '가치', '수립', '목표', '포함', '결정', '참가자', '여부', '내용', '시간', '배경', '제공',
                     '이용', '준지', '진행', '도모', '발전', '상품', '정보', '기반', '사업', '처리', '입니다', '합니다',
                       '같습니다', '것입니다', '있습니다', '돕는다', '됩니다', '시킵니다', '다음과', '다음은', '이상', '본', '모든', '빠른',
                        '빠르고', '정확한', '위함', '은', '는', '이', '가', '을', '를', '하여', '하기', '및', '에서', '과', '와', '의',
                         '위한', '으로', '이고', '시키기', '시키고', '것', '위해', '있는', '등', '통해', '통하여', '통해서',
                          '하는', '한', '있도록', '더', '에서', '보다', '이를', '같은', '다른', '느끼는', '할 수', '쉽게',
                           '원하는', '새로운', '하고', '시키는', '각각의', '하며', '또한', '거쳐', '등의', '된', '하거나', '가장',
                            '최적의', '기반으로', '테스트', '다양한', '이런', '이러한', '에서', '나는', '해서', '따라', '따라서', '에',
                             '하게', '보다', '이용한', '만들고', '사용한', '활용한', '1.', '2.', '3.', '4.', '5.', '6.',
                              '7.', '8.', '9.', '(1)', '(2)', '(3)', '(4)', '(5)', '(6)', ' (7)', '(8)', '(9)', '주요',
                               '중요한', '매우', '것이', '있고', '하도록', '이루기', '로', '여러', '되며', '-', '.', ',',
                                '따른', '두고', '담고', '있도록', '모으고', '모아', '담아', '두고', '의도한', '해당', '형식', '경우',
                                 '추가', '데이터', '모델', '분석', '수', '시스템', '기획', '수집', '경험', '객체', '인식', '안', '검증', '소프트웨어', '비용'})

# Kiwi 분석기 초기화
kiwi.prepare()
def tokenize(file_name, file_path):
    doc = ''  
    result = ''
    명사 = ('NN')    
    # 경로에 있는 docx 파일 txt로 변환 후 변수 doc 저장
    doc = docx2txt.process(file_path+file_name)
    # doc 문자열을 형태소분석해 토큰화 후 변수 kiwi_tokenize 저장
    kiwi_tokenize = kiwi.tokenize(doc)
    for i in kiwi_tokenize:
        # 형태소 분석 결과에서 명사추출
        if i[1].startswith(명사):
            # 불용어 처리 
            if i[0] not in stopwords:
                # 변수에 저장
                result += i[0] + ' '
  
    return result